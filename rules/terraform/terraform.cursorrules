# TERRAFORM INFRASTRUCTURE RULES

## Project Structure
- Modular Design: Each directory represents a deployable unit
- Ordered Dependencies: Deploy in numbered order (00, 01, 02...)
- Single Responsibility: Each module handles one logical concern
- Commons Pattern: Shared resources in `08_commons/`

## File Organization
- `00-variables.tf`: Input variables with descriptions
- `01-data.tf`: Data sources and external references  
- `02-main.tf`: Provider and backend configuration
- `03-*.tf`: Resource definitions (numbered by type)
- `04-outputs.tf`: Output values and CLI examples

**Example Module Structure**:
```
module_name/
├── 00-variables.tf     # All input variables with descriptions
├── 01-data.tf          # External data source lookups
├── 02-main.tf          # Provider and version requirements
├── 03-resource-type.tf # Primary resource definitions
├── 04-security.tf      # Security groups, IAM roles
├── 05-networking.tf    # Network-related resources
├── 06-outputs.tf       # All outputs with CLI examples
└── README.md          # Module documentation
```

## Variable Organization
- Group Similar Variables: Organize variables by logical sections with clear headers
- Section Headers: Use commented section dividers for readability
- Logical Grouping: Group by: Application config, VPC config, Subnet config, Database config, etc.
- Default Values Preferred: Use default values in variables.tf files instead of separate .tfvars files for environment-specific configurations

## Naming Conventions
```hcl
# Resources: service-purpose-modifier
resource "aws_s3_bucket" "app_assets_bucket" {}

# Variables: snake_case with clear intent
variable "database_instance_class" {}

# Outputs: descriptive with usage context
output "db_connection_string" {}
```

## Backend Configuration Standards
- No Backend in Modules: Individual modules should NEVER include backend configuration blocks
- Centralized State Management: Backend configuration is handled at the environment level only
- Environment-Level Backend: Only `infra/environments/{env}/` directories should contain backend configuration

## Version Standards
- Consistent Version: Use Terraform `~> 1.5.0` across ALL modules and environments
- AWS Provider: Use AWS provider `~> 5.0` for consistency and latest features
- Version Constraints: Always specify version constraints to prevent unexpected updates

**Standard Provider Block**:
```hcl
terraform {
  required_version = "~> 1.5.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Environment = var.environment
      Project     = var.app_name
      ManagedBy   = "terraform"
    }
  }
}
```

## Data Source Patterns
- Use Filter Instead of Tags: ALL modules must use `filter` blocks for external resource discovery, never `tags` blocks
- Consistent Naming Pattern: Use `tag:Name` filter with environment-based naming for predictable resource discovery
- Conditional Data Sources: Use `count` parameter for optional resource lookups to handle missing resources gracefully
- Standard Pattern: All modules should follow conditional lookup pattern for maximum flexibility
- Error Handling: Always include proper validation when using conditional data sources
- Documentation: Include both filter-based and direct-reference examples in module outputs

**Example Patterns**:
```hcl
# ✅ CORRECT: Use filter with tag:Name for consistent discovery
data "aws_vpc" "main" {
  count = var.vpc_id == "" ? 1 : 0
  filter {
    name   = "tag:Name"
    values = ["${var.app_name}-${var.environment}-vpc"]
  }
}

# ❌ INCORRECT: Never use tags block - inconsistent and inflexible
data "aws_vpc" "main" {
  tags = {
    Name = "${var.app_name}-${var.environment}-vpc"
  }
}
```

## Security & Compliance
- Least Privilege: Minimum required permissions for all IAM roles and policies
- Policy Separation: Logical grouping of permissions by function
- Service Users: External access with specific resource targeting only
- No Hardcoded Credentials: Use IAM roles inside VPC, never hardcode secrets
- KMS Encryption: Customer-managed keys for all encryption requirements
- S3 Security: Server-side encryption enabled for all buckets
- RDS Security: Encryption at rest and in transit for all databases
- Secrets Manager: Automatic encryption for all sensitive configuration
- CloudTrail: Full audit logging for compliance requirements
- CloudWatch Logs: Application and system logs with proper retention
- Metric Filters: Automated alerting on security and error events
- Log Retention: Cost-optimized retention periods for compliance needs

## Cost Optimization
- Lifecycle Rules: S3 object transitions to cheaper storage classes
- Log Retention: Appropriate retention periods to control costs
- Instance Sizing: Right-sized instances for actual workload requirements
- Reserved Capacity: Use reserved instances for predictable production workloads
- Spot Instances: Use spot instances for non-critical or batch workloads
- Storage Classes: Optimize S3 storage classes based on access patterns
- Auto Scaling: Implement auto scaling to optimize resource usage
- Resource Cleanup: Implement lifecycle policies to clean up unused resources

## Code Structure Best Practices
- Clear File Purpose: File names immediately indicate content and purpose
- Logical Flow: Variables → Data → Provider → Resources → Outputs
- Descriptive Comments: Section headers and resource explanations
- Consistent Formatting: Use `terraform fmt` for consistent styling
- Resource Grouping: Group related resources in numbered files (03-database.tf, 04-compute.tf)
- Readable Names: Use descriptive resource and variable names that explain purpose
- Documentation: Include inline comments explaining non-obvious configurations

## Deployment Process
```bash
# Template for each module
cd infra/{module_name}
terraform init
terraform plan
terraform apply
```

## Post-Deployment Verification
- Always verify with AWS CLI: After terraform deployments, use AWS CLI to confirm actual resource state
- Audit for orphaned resources: Check for resources not managed by current Terraform state
- Validate cleanup operations: Ensure deleted resources are actually removed from AWS
- Cross-reference naming: Verify resource names match expected patterns to catch duplicates

**Standard Verification Commands**:
```bash
# Core infrastructure audit
aws ec2 describe-vpcs --region us-east-1 --output json
aws ec2 describe-instances --region us-east-1 --output json  
aws rds describe-db-instances --region us-east-1 --output json
aws elbv2 describe-load-balancers --region us-east-1 --output json
aws elbv2 describe-target-groups --region us-east-1 --output json

# Check for orphaned resources in specific VPC
aws ec2 describe-security-groups --region us-east-1 --filters "Name=vpc-id,Values=VPC_ID"
aws ec2 describe-subnets --region us-east-1 --filters "Name=vpc-id,Values=VPC_ID"
aws ec2 describe-route-tables --region us-east-1 --filters "Name=vpc-id,Values=VPC_ID"

# Verify resource naming patterns
aws ec2 describe-vpcs --region us-east-1 --filters "Name=tag:Name,Values=*app-name*"
```

## Standards Validation
- Data Source Pattern: All external resource lookups use `filter` blocks (never `tags` blocks)
- Backend Configuration: Modules have NO backend blocks (only environment-level configs)
- Terraform Version: All modules use consistent Terraform `~> 1.5.0` and AWS provider `~> 5.0`
- Naming Convention: Resources follow `${var.app_name}-${var.environment}-resource-type` pattern
- Conditional Lookups: Data sources use `count` parameter for optional resource discovery
- Variable Organization: Variables grouped by logical sections with clear headers
- File Structure: Files follow numbered naming convention (00-variables.tf, 01-data.tf, etc.)
- Environment Integration: Modules use remote state for dependency management
- Tagging Compliance: All resources include required tags (Name, Environment, Project, Module, ManagedBy)
- Code Formatting: All files formatted with `terraform fmt`

**Automated Validation Commands**:
```bash
# Check for deprecated tags usage in data sources
grep -r "tags = {" infra/ --include="*.tf" | grep "data\."

# Verify filter pattern usage
grep -r "filter {" infra/ --include="*.tf" | grep -A 2 "tag:Name"

# Find backend blocks in base modules (should be empty)
find infra/ -name "*.tf" -not -path "*/environments/*" -exec grep -l "backend" {} \;

# Check Terraform version consistency
grep -r "required_version" infra/ --include="*.tf" | grep -v "~> 1.5.0"

# Verify AWS provider version consistency  
grep -r "version.*aws" infra/ --include="*.tf" | grep -v "~> 5.0"

# Check code formatting
find infra/ -name "*.tf" -exec terraform fmt -check {} \;
```

## Tagging Strategy
```hcl
tags = {
  Name        = "${var.app_name}-${var.environment}-resource-name"
  Environment = var.environment
  Project     = var.app_name
  Module      = "module-name"
  ManagedBy   = "terraform"
}
```

## Testing Strategy
- Use `terraform plan`
- AWS CLI Verification: Always validate actual AWS resource state after deployments
- Orphan Detection: Use AWS CLI to identify resources not in Terraform state
- Cleanup Validation: Verify deleted resources are actually removed from AWS account
- Naming Conflict Detection: Check for duplicate resource names causing "multiple resources matched" errors 